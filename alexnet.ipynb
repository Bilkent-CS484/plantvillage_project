{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, txt_loc, transform=None):\n",
    "        print(\"Initializing image dataset.\")\n",
    "        self.image_labels = [] \n",
    "        self.image_paths = self.find_full_paths(txt_loc)\n",
    "        self.transform = transform\n",
    "        print(f\"Total images found: {len(self.image_paths)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path, label = self.image_paths[index]\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            print(f\"Loaded image {index + 1}/{len(self.image_paths)}: {img_path}\")\n",
    "            return image, torch.tensor(label, dtype=torch.long)\n",
    "        except IOError:\n",
    "            print(f\"Error loading image: {img_path}\")\n",
    "            return None, None\n",
    "\n",
    "    def find_file_by_suffix(self, directory, filename_suffix):\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for filename in files:\n",
    "                if filename.endswith(filename_suffix):\n",
    "                    return os.path.join(root, filename)\n",
    "        return None\n",
    "\n",
    "    def find_full_paths(self, txt_loc):\n",
    "       data_dirs = os.listdir(\"color/\")\n",
    "       final_paths = []\n",
    "       with open(txt_loc, 'r') as infile:\n",
    "           lines = [line.strip() for line in infile.readlines()]\n",
    "        \n",
    "       for line in lines:\n",
    "            parts = line.rsplit(' ', 1)  # Split from the end to separate the label\n",
    "            filename = parts[0]\n",
    "            label = int(parts[1])  # Convert label part to integer\n",
    "            directory_index = label - 1  # Adjust index based on label to find directory\n",
    "            file_location = f'color/{data_dirs[directory_index]}/'\n",
    "            full_path = self.find_file_by_suffix(file_location, filename)\n",
    "            if full_path:\n",
    "                final_paths.append((full_path, label))\n",
    "            else:\n",
    "                print(f\"File not found: {filename} in {file_location}\")\n",
    "       return final_paths\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:16:03.297617300Z",
     "start_time": "2024-04-18T13:16:03.284630300Z"
    }
   },
   "id": "5b97742a309eea73"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=31, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=31):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = AlexNet().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:16:04.754064800Z",
     "start_time": "2024-04-18T13:16:04.382780500Z"
    }
   },
   "id": "3b61342a1e5e132e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:18:11.863293600Z",
     "start_time": "2024-04-18T13:16:12.038312900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing image dataset.\n",
      "File not found: FREC_C.Rust 9996.JPG in color/Apple___Cedar_apple_rust/\n",
      "File not found: APPLE_HL 7902.JPG in color/Apple___healthy/\n",
      "File not found: BLUEBERRY_HL 5494.JPG in color/Blueberry___healthy/\n",
      "File not found: FAM_B.Msls 4430.JPG in color/Grape___Esca_(Black_Measles)/\n",
      "File not found: UF.Citrus_HLB_Lab 7486.JPG in color/Orange___Haunglongbing_(Citrus_greening)/\n",
      "File not found: Rutg._HL 2405.JPG in color/Peach___healthy/\n",
      "File not found: SOYBEAN_HL 2777.JPG in color/Soybean___healthy/\n",
      "File not found: RS_Erly.B 6341 (Kelsee Baranowski's conflicted copy 2015-10-06).JPG in color/Tomato___Early_blight/\n",
      "File not found: TOMATO_HL 9853.JPG in color/Tomato___healthy/\n",
      "File not found: YLCV_GCREC 1946.JPG in color/Tomato___Tomato_Yellow_Leaf_Curl_Virus/\n",
      "Total images found: 34011\n",
      "34011\n",
      "Initializing image dataset.\n",
      "File not found: UF.GRC_BS_Lab Leaf 0381.JPG in color/Tomato___Bacterial_spot/\n",
      "Total images found: 8498\n",
      "8498\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(227), #alexnet size\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = ImageDataset(txt_loc='./train.txt', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "print(len(train_dataset))\n",
    "\n",
    "test_dataset = ImageDataset(txt_loc='./test.txt', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "print(len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T13:18:26.277410200Z",
     "start_time": "2024-04-18T13:18:24.959682700Z"
    }
   },
   "id": "ca7bea57a3a30377"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'custom_alexnet_plantvillage.pth')\n",
    "print('Training complete and model saved')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-18T13:18:29.828550400Z"
    }
   },
   "id": "4f5882ac0a473d65"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 12.807292146211214%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total}%')\n",
    "\n",
    "evaluate_model()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T06:23:52.438060800Z",
     "start_time": "2024-04-16T06:20:31.923561400Z"
    }
   },
   "id": "7638f5d6b972aa94"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
